{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6460154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import camb\n",
    "from scipy.interpolate import interp1d\n",
    "from classy import Class\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams.update({'axes.labelsize' : 20})\n",
    "plt.rcParams.update({'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe452b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classy\n",
    "# classy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f194533",
   "metadata": {},
   "source": [
    "### Original author for this updated notebook: Jamie Sullivan, github @jmsull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-orlando",
   "metadata": {},
   "source": [
    "Matter power spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "absent-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuFlag=True\n",
    "bolt_names = ['h','Omr','Omb','Omcb','ns','Y_p','Neff','smnu','As']\n",
    "\n",
    "bolt_cosmo = [0.7,5.042e-5,0.046,0.224+0.046,1.0,0.24,3.046,0.06,1e-10*np.exp(3.043)] #this is the choice of Planck TTTEEE in class for nu\n",
    "cosmo_dict = dict(zip(bolt_names,bolt_cosmo))\n",
    "# cosmo_dict['Omm'] = cosmo_dict['Omcb']+cosmo_dict['smnu']/93.14/cosmo_dict['h']**2\n",
    "cosmo_dict['Omcdm'] = cosmo_dict['Omcb']-cosmo_dict['Omb'] #need this line here or perturbations will fail\n",
    "k = np.logspace(-4,1,2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "owned-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ref = {\n",
    "    'recombination': 'RECFAST',\n",
    "    'tol_ncdm_bg':1.e-10,\n",
    "    # 'recfast_Nz0':100000,\n",
    "    'tol_thermo_integration':1.e-6,\n",
    "    # 'recfast_x_He0_trigger_delta':0.01,\n",
    "    # 'recfast_x_H0_trigger_delta':0.01,\n",
    "    'k_min_tau0':0.002,\n",
    "    'k_max_tau0_over_l_max':3.,\n",
    "    'k_step_sub':0.015,\n",
    "    'k_step_super':0.0001,\n",
    "    'k_step_super_reduction':0.1,\n",
    "    'start_small_k_at_tau_c_over_tau_h':0.0004,\n",
    "    'start_large_k_at_tau_h_over_tau_k':0.05,\n",
    "    # 'tight_coupling_trigger_tau_c_over_tau_h':0.005,\n",
    "    # 'tight_coupling_trigger_tau_c_over_tau_k':0.008,\n",
    "\n",
    "\n",
    "    'evolver':1,\n",
    "    'tight_coupling_trigger_tau_c_over_tau_h':4.1e-4,\n",
    "    'tight_coupling_trigger_tau_c_over_tau_k':6.1e-5,\n",
    "\n",
    "    'start_sources_at_tau_c_over_tau_h':0.006,\n",
    "    'l_max_g':50,\n",
    "    'l_max_pol_g':50,\n",
    "    'l_max_ur':50,\n",
    "    'l_max_ncdm':50,\n",
    "    'tol_perturbations_integration':1.e-6,\n",
    "    'perturbations_sampling_stepsize':0.01,\n",
    "    'l_logstep':1.026,\n",
    "    'l_linstep':25,\n",
    "    'hyper_sampling_flat':12.,\n",
    "    'hyper_sampling_curved_low_nu':10.,\n",
    "    'hyper_sampling_curved_high_nu':10.,\n",
    "    'hyper_nu_sampling_step':10.,\n",
    "    'hyper_phi_min_abs':1.e-10,\n",
    "    'hyper_x_tol':1.e-4,\n",
    "    'hyper_flat_approximation_nu':1.e6,\n",
    "    'q_linstep':0.20,\n",
    "    'q_logstep_spline':20.,\n",
    "    'q_logstep_trapzd':0.5,\n",
    "    'q_numstep_transition':250,\n",
    "    'transfer_neglect_delta_k_S_t0':100.,\n",
    "    'transfer_neglect_delta_k_S_t1':100.,\n",
    "    'transfer_neglect_delta_k_S_t2':100.,\n",
    "    'transfer_neglect_delta_k_S_e':100.,\n",
    "    'transfer_neglect_delta_k_V_t1':100.,\n",
    "    'transfer_neglect_delta_k_V_t2':100.,\n",
    "    'transfer_neglect_delta_k_V_e':100.,\n",
    "    'transfer_neglect_delta_k_V_b':100.,\n",
    "    'transfer_neglect_delta_k_T_t2':100.,\n",
    "    'transfer_neglect_delta_k_T_e':100.,\n",
    "    'transfer_neglect_delta_k_T_b':100.,\n",
    "    'neglect_CMB_sources_below_visibility':1.e-30,\n",
    "    'transfer_neglect_late_source':3000.,\n",
    "    'halofit_k_per_decade':3000.,\n",
    "    'l_switch_limber':40.,\n",
    "    'accurate_lensing':1,\n",
    "    'num_mu_minus_lmax':1000.,\n",
    "    'delta_l_max':1000.\n",
    "}\n",
    "\n",
    "# additional precision parameters for neutrinos only\n",
    "class_ref_nu = {\n",
    "    'radiation_streaming_approximation':2,\n",
    "    'radiation_streaming_trigger_tau_over_tau_k':240.,\n",
    "    'radiation_streaming_trigger_tau_c_over_tau':100.,\n",
    "    'ur_fluid_approximation':3,\n",
    "    'ur_fluid_trigger_tau_over_tau_k':50.,\n",
    "    'ncdm_fluid_approximation':3,\n",
    "    'ncdm_fluid_trigger_tau_over_tau_k':51.,\n",
    "    'tol_ncdm_synchronous':1.e-10,\n",
    "    'tol_ncdm_newtonian':1.e-10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satisfactory-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_camb(cosmo_dict,k,z,nu=False):\n",
    "    cosmo_dict['Omcdm'] = cosmo_dict['Omcb']-cosmo_dict['Omb']\n",
    "\n",
    "    pars = camb.CAMBparams()\n",
    "    pars.set_cosmology(H0=cosmo_dict['h']*100,\n",
    "                       ombh2=cosmo_dict['Omb']*cosmo_dict['h']**2,\n",
    "                       omch2=cosmo_dict['Omcdm']*cosmo_dict['h']**2,\n",
    "                       mnu=cosmo_dict['smnu'] if nuFlag else 0., \n",
    "                       num_massive_neutrinos=1 if nuFlag else 0,\n",
    "\n",
    "                       YHe=cosmo_dict['Y_p'],\n",
    "                       omk=0, tau=0.06) #fixed parameters, Planck neutrinos\n",
    "    pars.set_accuracy(AccuracyBoost=3.0, lAccuracyBoost=3.0, DoLateRadTruncation=False)\n",
    "    pars.InitPower.set_params(ns=cosmo_dict['ns'],\n",
    "                              As=cosmo_dict['As'])\n",
    "\n",
    "    pars.set_matter_power(redshifts=[0.])#, kmax=kmax/h) \n",
    "    pars.share_delta_neff = True \n",
    "\n",
    "    results = camb.get_results(pars)\n",
    "    zmin,zmax = 0, 2\n",
    "    nz=3\n",
    "    camb_interp = camb.get_matter_power_interpolator(pars,zmin=zmin,zmax=zmax,nz_step=nz,nonlinear=False)\n",
    "    pinterp = camb_interp.P #defaults #takes (z,k) pairs\n",
    "    return pinterp(z,k), results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115672c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organizational-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should really just make a private toolbox with these functions somewhere...\n",
    "def run_class(cosmo_dict,k,z,nu=False,pk=False,gauge='synchronous'):\n",
    "    '''Simple call to boltzmann code using input cosmology parameter vector. k in h/Mpc.'''\n",
    "    #setup\n",
    "    if('h' not in cosmo_dict.keys()):\n",
    "        h = cosmo_dict['H0']/100.\n",
    "    elif('H0' not in cosmo_dict.keys()):\n",
    "        cosmo_dict['H0'] = cosmo_dict['h']*100.\n",
    "        h = cosmo_dict['h']\n",
    "    if('Omcdm' not in cosmo_dict.keys()):\n",
    "        cosmo_dict['Omcdm'] = cosmo_dict['Omcb']-cosmo_dict['Omb']\n",
    "        # cosmo_dict['Omcdm'] = cosmo_dict['Omm']-cosmo_dict['Omb']\n",
    "    c,G = 2.99792e5,4.30071e-9 \n",
    "    h=cosmo_dict['h']\n",
    "    if(nu): \n",
    "        #use Planck single massive neutrino if using neutrinos\n",
    "        N_ncdm=1\n",
    "        m_ncdm=0.06 \n",
    "    else:\n",
    "        N_ncdm=0\n",
    "        m_ncdm=0 \n",
    "    \n",
    "    N_ur=3.046-N_ncdm\n",
    "    # N_ur = 3.046\n",
    "    print(\"Nur: {0:.3f}, Nncdm: {1:.3f}, mncdm: {2:.3f}\".format(N_ur,N_ncdm,m_ncdm))\n",
    "    \n",
    "    ceng = Class()\n",
    "    #gross but don't want to look up how to do it right now\n",
    "    if(nuFlag): \n",
    "        ceng.set({'h':h,\n",
    "              'omega_b':cosmo_dict['Omb']*h**2,\n",
    "              'omega_cdm':cosmo_dict['Omcdm']*h**2,\n",
    "              #'omega_r':cosmo_dict['Omr']*h**2,\n",
    "              'n_s':cosmo_dict['ns'],\n",
    "              'A_s':cosmo_dict['As'],\n",
    "              'gauge':gauge,\n",
    "              'N_ur': 2.0308,\n",
    "              'N_ncdm': N_ncdm,\n",
    "              'T_ncdm': 0.7133,  # IMPORTANT, see page 11 of arxiv:1104.2935\n",
    "#               'T_ncdm': (4/11)**(1/3),  \n",
    "              'm_ncdm': m_ncdm,\n",
    "              'YHe': cosmo_dict['Y_p'],\n",
    "              'ncdm_fluid_approximation':3,\n",
    "              'z_reio': 7.6711\n",
    "              })\n",
    "    else: \n",
    "        ceng.set({'h':h,\n",
    "              'omega_b':cosmo_dict['Omb']*h**2,\n",
    "              'omega_cdm':cosmo_dict['Omcdm']*h**2,\n",
    "              #'omega_r':cosmo_dict['Omr']*h**2,\n",
    "              'n_s':cosmo_dict['ns'],\n",
    "              'A_s':cosmo_dict['As'],\n",
    "              'gauge':gauge,\n",
    "              'N_ur': N_ur,\n",
    "#               'N_ncdm': N_ncdm,\n",
    "#               'm_ncdm': m_ncdm,\n",
    "              'YHe': cosmo_dict['Y_p'],\n",
    "              'ncdm_fluid_approximation':3,\n",
    "              'z_reio': 7.6711,   \n",
    "#               'k_per_decade_for_pk':4000 seems it is impossible to make tks give more ks???\n",
    "              })\n",
    "    print(m_ncdm)\n",
    "    print(ceng.pars)\n",
    "    #need lower z_max ow issues long complaint, need z<z_rec for pk to work apparently\n",
    "    ceng.set(class_ref)\n",
    "    ceng.set(class_ref_nu)\n",
    "    ceng.set({'output':  'mPk, mTk','P_k_max_1/Mpc':10.0})\n",
    "    ceng.compute()\n",
    "    plin=[]\n",
    "    for ki in k: plin.append(ceng.pk(ki*h,z)*h**3) \n",
    "    # get P(k) at redshift z=0\n",
    "    transfers = ceng.get_transfer(z)\n",
    "    ceng.struct_cleanup()\n",
    "    ceng.empty()\n",
    "        \n",
    "    return transfers,plin,ceng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caroline-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bolt_cosmo = [0.7,5.042e-5,0.046,0.224+0.046,1.0,0.24,3.046,1e-10*np.exp(3.043)] #this is the choice of Planck TTTEEE in class for nu\n",
    "# ts0,pL0,ceng = run_class(cosmo_dict,k[:10],np.exp(0)-1,nu=nuFlag,pk=True,gauge='synchronous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diverse-syndrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nur: 2.046, Nncdm: 1.000, mncdm: 0.060\n",
      "0.06\n",
      "{'h': 0.7, 'omega_b': 0.022539999999999998, 'omega_cdm': 0.10976, 'n_s': 1.0, 'A_s': 2.096805313253679e-09, 'gauge': 'newtonian', 'N_ur': 2.0308, 'N_ncdm': 1, 'T_ncdm': 0.7133, 'm_ncdm': 0.06, 'YHe': 0.24, 'ncdm_fluid_approximation': 3, 'z_reio': 7.6711}\n"
     ]
    }
   ],
   "source": [
    "ts0,pL0N,ceng = run_class(cosmo_dict,k,np.exp(0)-1,nu=nuFlag,pk=True,gauge='newtonian')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sophisticated-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "pCAMB, camb_results = run_camb(cosmo_dict,k,np.exp(0)-1,nu=nuFlag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alleged-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #newtonian vs synch gauge\n",
    "# plt.plot(k,pCAMB/pL0 - 1,label='Synchronous')\n",
    "# plt.plot(k,pCAMB/pL0N - 1 ,label='Newtonian')\n",
    "# plt.xscale('log')\n",
    "# plt.ylabel(r'$\\frac{P_{\\rm{CAMB}}}{P_{\\rm{CLASS}}} - 1$',fontsize=20)\n",
    "# plt.xlabel(r'$k \\ h/\\rm{Mpc} $',fontsize=20)\n",
    "# plt.axhline(0,ls=':',c='k')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stock-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuFlag=False\n",
    "# tsnonuN,pL0nou,_ = run_class(cosmo_dict,k_dense,np.exp(0)-1,nu=nuFlag,pk=True,gauge='newtonian')\n",
    "# _,pL0nouS,_ = run_class(cosmo_dict,k,np.exp(0)-1,nu=nuFlag,pk=True,gauge='synchronous')\n",
    "# pCAMBnonnu,_ = run_camb(cosmo_dict,k,np.exp(0)-1,nu=nuFlag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assisted-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #nonu comparison\n",
    "# plt.title('nonu')\n",
    "# plt.plot(k,pCAMBnonnu/pL0nouS,label='Synch')\n",
    "# # plt.plot(k,pCAMBnonnu/pL0nou,label='Newt')\n",
    "# plt.xscale('log')\n",
    "# plt.ylabel(r'$\\frac{P_{\\rm{CAMB}}}{P_{\\rm{CLASS}}}$',fontsize=20)\n",
    "# plt.xlabel(r'$k \\ h/\\rm{Mpc} $',fontsize=20)\n",
    "# plt.axhline(1,ls=':',c='k')\n",
    "# plt.legend()\n",
    "# plt.xlim(10**(-2.5),10**0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513280ba",
   "metadata": {},
   "source": [
    "# Perturbation time!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea5d67",
   "metadata": {},
   "source": [
    "jms 6/15/22 - **NB** Had to change the CLASS source code (as EXPLICILTY DIRECTED TO by CLASS) to be able to get high-redshift perturbations to run. \n",
    "This is the no neutrino run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ddf663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copied from class_public notebook - many_times - dropping the things needed to make their beautiful figure for brevity\n",
    "#i.e. damping scale etc\n",
    "\n",
    "#commented out values are the original notebook values from class_public\n",
    "z_max_pk = 460000 #46000go to very high maximum redshift to see what is happening\n",
    "k_per_decade = 400#40#     # number of k values, controls final resolution\n",
    "k_min_tau0 = 40.       # this value controls the minimum k value in the figure (it is k_min * tau0)\n",
    "P_k_max_inv_Mpc =1.0   # this value is directly the maximum k value in the figure in Mpc\n",
    "tau_num_early = 2000#200#   # number of conformal time values before recombination, controls final resolution\n",
    "tau_num_late = 200     # number of conformal time values after recombination, controls final resolution\n",
    "tau_ini = 10#.1#          # first value of conformal time in Mpc\n",
    "\n",
    "# Cosmological parameters and other CLASS parameters\n",
    "# jms: 6/15/22 Below I commented out the parameters that I used before (some of which are no longer accepted)\n",
    "common_settings = {# which output? transfer functions only\n",
    "                   'output':'mTk, vTk',\n",
    "                   'h':cosmo_dict['h'],\n",
    "                   'omega_b':cosmo_dict['Omb']*cosmo_dict['h']**2,\n",
    "                   'omega_cdm':cosmo_dict['Omcdm']*cosmo_dict['h']**2,\n",
    "                   'n_s':cosmo_dict['ns'],\n",
    "                   'gauge':'newtonian',\n",
    "                   'N_ur': cosmo_dict['Neff'],#-1,\n",
    "                   'N_ncdm': 0,\n",
    "#                    'm_ncdm': 0.06,\n",
    "                   'YHe': cosmo_dict['Y_p'],\n",
    "                   'P_k_max_1/Mpc':10.0,\n",
    "                   'z_max_pk':z_max_pk,\n",
    "#                    'recfast_Nz0':z_max_pk*2.,\n",
    "#                    'recfast_z_initial':z_max_pk+1.,\n",
    "                   'k_per_decade_for_pk':k_per_decade,\n",
    "                   'k_per_decade_for_bao':k_per_decade,\n",
    "#                    'perturb_sampling_stepsize':'0.05',\n",
    "#                    'ncdm_fluid_approximation':3,\n",
    "                    #default is to use HyRec, but I want to see if the discrepancy I am seeing is due to HyRec\n",
    "#                    'recombination':'RECFAST', #this seems to change nothing?\n",
    "                   'z_reio' : 7.6711\n",
    "\n",
    "                  }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41dfd096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call CLASS \n",
    "M = Class()\n",
    "M.set(common_settings)\n",
    "M.set(class_ref) #When I ran this before, did not use the ref settings, using them now though...\n",
    "M.set(class_ref_nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916b5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': 'mTk, vTk', 'h': 0.7, 'omega_b': 0.022539999999999998, 'omega_cdm': 0.10976, 'n_s': 1.0, 'gauge': 'newtonian', 'N_ur': 3.046, 'N_ncdm': 0, 'YHe': 0.24, 'P_k_max_1/Mpc': 10.0, 'z_max_pk': 460000, 'k_per_decade_for_pk': 400, 'k_per_decade_for_bao': 400, 'z_reio': 7.6711, 'recombination': 'RECFAST', 'tol_ncdm_bg': 1e-10, 'tol_thermo_integration': 1e-06, 'k_min_tau0': 0.002, 'k_max_tau0_over_l_max': 3.0, 'k_step_sub': 0.015, 'k_step_super': 0.0001, 'k_step_super_reduction': 0.1, 'start_small_k_at_tau_c_over_tau_h': 0.0004, 'start_large_k_at_tau_h_over_tau_k': 0.05, 'evolver': 1, 'tight_coupling_trigger_tau_c_over_tau_h': 0.00041, 'tight_coupling_trigger_tau_c_over_tau_k': 6.1e-05, 'start_sources_at_tau_c_over_tau_h': 0.006, 'l_max_g': 50, 'l_max_pol_g': 50, 'l_max_ur': 50, 'l_max_ncdm': 50, 'tol_perturbations_integration': 1e-06, 'perturbations_sampling_stepsize': 0.01, 'l_logstep': 1.026, 'l_linstep': 25, 'hyper_sampling_flat': 12.0, 'hyper_sampling_curved_low_nu': 10.0, 'hyper_sampling_curved_high_nu': 10.0, 'hyper_nu_sampling_step': 10.0, 'hyper_phi_min_abs': 1e-10, 'hyper_x_tol': 0.0001, 'hyper_flat_approximation_nu': 1000000.0, 'q_linstep': 0.2, 'q_logstep_spline': 20.0, 'q_logstep_trapzd': 0.5, 'q_numstep_transition': 250, 'transfer_neglect_delta_k_S_t0': 100.0, 'transfer_neglect_delta_k_S_t1': 100.0, 'transfer_neglect_delta_k_S_t2': 100.0, 'transfer_neglect_delta_k_S_e': 100.0, 'transfer_neglect_delta_k_V_t1': 100.0, 'transfer_neglect_delta_k_V_t2': 100.0, 'transfer_neglect_delta_k_V_e': 100.0, 'transfer_neglect_delta_k_V_b': 100.0, 'transfer_neglect_delta_k_T_t2': 100.0, 'transfer_neglect_delta_k_T_e': 100.0, 'transfer_neglect_delta_k_T_b': 100.0, 'neglect_CMB_sources_below_visibility': 1e-30, 'transfer_neglect_late_source': 3000.0, 'halofit_k_per_decade': 3000.0, 'l_switch_limber': 40.0, 'accurate_lensing': 1, 'num_mu_minus_lmax': 1000.0, 'delta_l_max': 1000.0, 'radiation_streaming_approximation': 2, 'ur_fluid_approximation': 3, 'ur_fluid_trigger_tau_over_tau_k': 50.0, 'ncdm_fluid_approximation': 3, 'ncdm_fluid_trigger_tau_over_tau_k': 51.0, 'tol_ncdm_synchronous': 1e-10, 'tol_ncdm_newtonian': 1e-10}\n"
     ]
    }
   ],
   "source": [
    "print(M.pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb98828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.compute() #This takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "495b7517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in a next run with the same values of tau, you may decrease z_max_pk from  460000  to  45570.849885589305\n"
     ]
    }
   ],
   "source": [
    "#Copied from CLASS many_times.ipynv\n",
    "\n",
    "# define conformal time sampling array\n",
    "times = M.get_current_derived_parameters(['tau_rec','conformal_age'])\n",
    "tau_rec=times['tau_rec']\n",
    "tau_0 = times['conformal_age']\n",
    "tau1 = np.logspace(np.log10(tau_ini),np.log10(tau_rec),tau_num_early)\n",
    "tau2 = np.logspace(np.log10(tau_rec),np.log10(tau_0),tau_num_late)[1:]\n",
    "tau2[-1] *= 0.999 # this tiny shift avoids interpolation errors\n",
    "tau = np.concatenate((tau1,tau2))\n",
    "tau_num = len(tau)\n",
    "\n",
    "background = M.get_background() # load background table\n",
    "#thermodynamics = M.get_thermodynamics() # load thermodynamics table\n",
    "\n",
    "background_tau = background['conf. time [Mpc]'] # read conformal times in background table\n",
    "background_z = background['z'] # read redshift\n",
    "background_z_at_tau = interp1d(background_tau,background_z)\n",
    "\n",
    "# check and inform user whether intiial arbitrary choice of z_max_pk was OK\n",
    "max_z_needed = background_z_at_tau(tau[0])\n",
    "if max_z_needed > z_max_pk:\n",
    "    print( 'you must increase the value of z_max_pk to at least ',max_z_needed)\n",
    "    () + 1  # this strange line is just a trick to stop the script execution there\n",
    "else:\n",
    "    print( 'in a next run with the same values of tau, you may decrease z_max_pk from ',z_max_pk,' to ',max_z_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1743894",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.zeros_like(tau) \n",
    "k_num = len( M.get_transfer(zz[0])['k (h/Mpc)']) #get number of k pts\n",
    "pkeys = ['k (h/Mpc)', 'd_g', 'd_b', 'd_cdm', 'd_ur', \n",
    "#          'd_ncdm[0]', #drop for nonu\n",
    "         'd_tot', 'phi', 'psi', 't_g', 't_b', 't_cdm', 't_ur', \n",
    "#          't_ncdm[0]',\n",
    "         't_tot']\n",
    "#get  all results\n",
    "perts = np.zeros((len(pkeys),tau_num,k_num))\n",
    "for i in range(tau_num):\n",
    "    zz[i] = background_z_at_tau(tau[i])\n",
    "    one_time = M.get_transfer(zz[i]) # transfer functions at each time \n",
    "    for s in range(len(pkeys)):\n",
    "        perts[s,i,:] = one_time[pkeys[s]][:] \n",
    "        #the [:] is not necessay I don't think, is a view of the array\n",
    "         #only use I have found so far for it is that a[:] = 10 assigns elementwise whereas a = 10 obviously does not\n",
    "    \n",
    "#flip things around to go from early to late times\n",
    "zz=zz[::-1]\n",
    "#convert z to x  #nice\n",
    "xx = np.log(1/(1+zz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the slice first for a particular k\n",
    "#this is lazy but just computing the full tau-k grid then slicing (we save the k value so it is fine to compare)\n",
    "def get_kslice(ktarget, eps=0.01):\n",
    "    k = perts[0,0,:]\n",
    "    itarget = np.where((k>ktarget-eps) & (k<ktarget+eps))[0][0]\n",
    "    return perts[:,:,itarget][:,::-1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save them\n",
    "sliced_pert_1 = get_kslice(0.3,eps=0.001)\n",
    "sliced_pert_2 = get_kslice(0.03,eps=0.001)\n",
    "sliced_pert_3 = get_kslice(1.0,eps=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the old modes\n",
    "np.savetxt('../../Bolt/test/data/zack_N_class_px_kp3_nofluid_nonu.dat',np.vstack([xx,sliced_pert_1]))\n",
    "np.savetxt('../../Bolt/test/data/zack_N_class_px_kp03_nofluid_nonu.dat',np.vstack([xx,sliced_pert_2]))\n",
    "np.savetxt('../../Bolt/test/data/zack_N_class_px_k1p0_nofluid_nonu.dat',np.vstack([xx,sliced_pert_3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e114a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some more while we are here\n",
    "np.savetxt('../../Bolt/test/data/zack_N_class_px_kp1_nofluid_nonu.dat',np.vstack([xx,\n",
    "                                                                                     get_kslice(0.1,eps=0.001)]))\n",
    "np.savetxt('../../Bolt/test/data/zack_N_class_px_kp5_nofluid_nonu.dat',np.vstack([xx,\n",
    "                                                                                     get_kslice(.5,eps=0.01)]))\n",
    "np.savetxt('../../Bolt/test/data/zack_N_class_px_kp01_nofluid_nonu.dat',np.vstack([xx,\n",
    "                                                                                     get_kslice(0.01,eps=0.001)]))\n",
    "np.savetxt('../../Bolt/test/data/zack_N_class_px_kp001_nofluid_nonu.dat',np.vstack([xx,\n",
    "                                                                                     get_kslice(0.001,eps=0.0001)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca049d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thermo = M.get_thermodynamics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6682228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scale factor a', 'z', 'conf. time [Mpc]', 'x_e', \"kappa' [Mpc^-1]\", 'exp(-kappa)', 'g [Mpc^-1]', 'Tb [K]', 'dTb [K]', 'w_b', 'c_b^2', 'tau_d'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thermo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../../Bolt/test/data/zack_N_class_px_nofluid_nonu_x_e.dat',\n",
    "np.vstack([thermo['scale factor a'],thermo[\"x_e\"], thermo['Tb [K]'], thermo['c_b^2']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f42aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (base)",
   "language": "python",
   "name": "cbase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
